# Sindhuja Chaduvula  
<img src="Photo.JPG" alt="Sindhuja Chaduvula" width="180" style="border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,0.1);" />

**Associate Applied ML Specialist | Responsible AI | Generative AI | AI Safety**

Toronto, Canada  
ğŸ“ University of Waterloo | ğŸ§  Vector Institute  

---

### ğŸ”— Links
- [GitHub](https://github.com/sindhujachaduvula)
- [LinkedIn](https://www.linkedin.com/in/sindhuja-chaduvula)
- [Resume (PDF)](resume.pdf)
- [Email Me](mailto:sindhu.chaduvula.21@gmail.com)

---

### ğŸ§  About Me
I am an **Applied ML Specialist** at the [Vector Institute](https://vectorinstitute.ai), working at the intersection of **AI Safety**, **Explainability**, and **AI Governance**.  
My work focuses on making **Large Language Models (LLMs)** and **multi-agent systems** more **transparent, trustworthy, and policy-aligned**, bridging research and responsible deployment.

I contributed as a **co-author** to *â€œExplainability and Interpretability in Agentic AI: A Survey Across the Agentic Loop (2025)â€*, where I led the **Explainability in Agentic AI** section.  
This research established a taxonomy of intrinsic, post-hoc, causal, and prototype-based explainability methods to improve transparency in **autonomous LLMs** and **agentic architectures**.  
It connects interpretability directly to governance frameworks such as the **EU AI Act**, **NIST AI Risk Management Framework**, and **ISO/IEC 42001** â€” reinforcing the link between **safe model design** and **regulatory compliance**.

My current research interests include:
- **AI Safety** and **AI Governance**  
- **Preference Alignment (DPO / ORPO / KTO / GRPO)**  
- **Explainable and Trust-weighted Multi-Agent Systems**  
- **Retrieval-Augmented Generation (RAG)** and Safe Reasoning Pipelines  
- **Ethical and Human-in-the-loop AI Deployment**

As part of my commitment to responsible innovation, I served as a **Reviewer for the AAAI 2026 Workshop on AI Governance (AIGOV)**, where I reviewed **LLM Governance and AI Safety papers** addressing explainability, human oversight, and alignment with global AI policy frameworks.

---

### ğŸ’¼ Experience

#### ğŸ§© **Vector Institute** â€” *Associate Applied ML Specialist* (Toronto, Canada)  
*Sept 2025 â€“ Present*  
- Conducting research on **AI Safety** and **Governance-Aware Explainability** frameworks for LLMs.  
- Generated 250+ synthetic scenarios across hiring and legal domains using GPT-4o Mini for bias-detection and fairness analysis.  
- Led the Explainability section of the *â€œExplainability and Interpretability in Agentic AIâ€* survey, defining intrinsic, post-hoc, and causal transparency methods.  
- Designed **trust-weighted interpretability** mechanisms for alignment auditing and safety verification in reasoning systems.

#### ğŸ’¡ **Vector Institute** â€” *Machine Learning Associate*  
*May 2025 â€“ Sept 2025*  
- Built a **LangChain + Qdrant RAG pipeline** to semantically index 1,000-page healthcare billing documents (âˆ’80% lookup time).  
- Implemented **hybrid retrieval** (OpenAI Embeddings + BM25) with rule-based safety filters (Recall@5 = 0.9, BERTScore = 0.8).  
- Delivered demos to leadership showcasing **responsible AI deployment pipelines** aligned with internal governance standards.

#### ğŸ§® **Genellipse** â€” *Data Scientist*  
*Aug 2024 â€“ Dec 2024*  
- Fine-tuned **Gemma 2B**, **LLaMA 3**, and **Mistral 7B** on 600 SEC 10-Q filings from 75 companies.  
- Automated data pipelines with EDGAR API and AWS S3 to create structured datasets for model training.  
- Delivered a governance-compliant PoC for **financial text generation**, achieving 40% structured accuracy while maintaining transparency and auditability.

#### ğŸ¤– **AIFocal Inc.** â€” *AI Engineer Intern*  
*Sept 2023 â€“ Oct 2023*  
- Built a **PDF-aware QA chatbot** using Gemma 2B and LangChain RAG integrated with safety filters.  
- Designed **semantic prompt routing** for multi-query reasoning, reducing hallucination rates by 12%.  
- Achieved 85% accuracy on long-context summarization QA benchmarks.

#### ğŸ“Š **Tata Consultancy Services** â€” *Assistant System Engineer*  
*Oct 2021 â€“ Dec 2022*  
- Developed telecom churn prediction models (Random Forest, XGBoost) with 87% accuracy.  
- Automated feature engineering and visualization pipelines, improving real-time decision analytics.

---

### ğŸ§© Projects
- ğŸ©º **Clinical Note Generator** â€“ Fine-tuned LLMs for mental-health documentation using structured SOAP/DAP templates.  
- ğŸ“Š **GenAI Billing Assistant** â€“ Multi-agent RAG system integrating SQL data and unstructured regulatory text for claim validation.  
- âš™ï¸ **SEC Filing Automation** â€“ Graph-based linking of financial tables and textual disclosures for explainable report generation.  
- ğŸ¤ **AIXpert Survey Paper** â€“ Co-authored the *Explainability and Interpretability in Agentic AI* survey (2025).

---

### ğŸ… Highlights
- ğŸ“ M.Eng., University of Waterloo â€” GPA 3.90 / 4.00  
- ğŸ“˜ Co-author â€” *Explainability and Interpretability in Agentic AI: A Survey Across the Agentic Loop (2025)*  
- ğŸ” **AAAI 2026 Reviewer â€” LLM Governance & AI Safety (AIGOV Workshop)**  
- ğŸ§± Hands-on with LoRA/QLoRA, Flash-Attention-2, and A100 distributed fine-tuning  
- ğŸŒ Open-source contributor to LangChain and CrewAI-based agentic frameworks  
- ğŸ§  Focus Areas: **AI Safety** Â· **Governance** Â· **Explainability** Â· **Trust Mechanisms** Â· **Responsible GenAI**

---

### ğŸ“« Contact
ğŸ“§ [sindhu.chaduvula.21@gmail.com](mailto:sindhu.chaduvula.21@gmail.com)  
ğŸ”— [LinkedIn](https://linkedin.com/in/sindhujachaduvula) | [GitHub](https://github.com/sindhujachaduvula)
