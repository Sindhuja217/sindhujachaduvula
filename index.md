# Sindhuja Chaduvula  
<img src="Photo.JPG" alt="Sindhuja Chaduvula" width="180" style="border-radius:50%; box-shadow:0 4px 12px rgba(0,0,0,0.1);" />

**Associate Applied ML Specialist | Responsible AI | Generative AI | AI Safety**

Toronto, Canada  
📍 University of Waterloo | 🧠 Vector Institute  

---

### 🔗 Links
- [GitHub](https://github.com/sindhujachaduvula)
- [LinkedIn](https://www.linkedin.com/in/sindhuja-chaduvula)
- [Resume (PDF)](resume.pdf)
- [Email Me](mailto:sindhu.chaduvula.21@gmail.com)

---

### 🧠 About Me
I am an **Applied ML Specialist** at the [Vector Institute](https://vectorinstitute.ai), working at the intersection of **AI Safety**, **Explainability**, and **AI Governance**.  
My work focuses on making **Large Language Models (LLMs)** and **multi-agent systems** more **transparent, trustworthy, and policy-aligned**, bridging research and responsible deployment.

I contributed as a **co-author** to *“Explainability and Interpretability in Agentic AI: A Survey Across the Agentic Loop (2025)”*, where I led the **Explainability in Agentic AI** section.  
This research established a taxonomy of intrinsic, post-hoc, causal, and prototype-based explainability methods to improve transparency in **autonomous LLMs** and **agentic architectures**.  
It connects interpretability directly to governance frameworks such as the **EU AI Act**, **NIST AI Risk Management Framework**, and **ISO/IEC 42001** — reinforcing the link between **safe model design** and **regulatory compliance**.

My current research interests include:
- **AI Safety** and **AI Governance**  
- **Preference Alignment (DPO / ORPO / KTO / GRPO)**  
- **Explainable and Trust-weighted Multi-Agent Systems**  
- **Retrieval-Augmented Generation (RAG)** and Safe Reasoning Pipelines  
- **Ethical and Human-in-the-loop AI Deployment**

As part of my commitment to responsible innovation, I served as a **Reviewer for the AAAI 2026 Workshop on AI Governance (AIGOV)**, where I reviewed **LLM Governance and AI Safety papers** addressing explainability, human oversight, and alignment with global AI policy frameworks.

---

### 💼 Experience

#### 🧩 **Vector Institute** — *Associate Applied ML Specialist* (Toronto, Canada)  
*Sept 2025 – Present*  
- Conducting research on **AI Safety** and **Governance-Aware Explainability** frameworks for LLMs.  
- Generated 250+ synthetic scenarios across hiring and legal domains using GPT-4o Mini for bias-detection and fairness analysis.  
- Led the Explainability section of the *“Explainability and Interpretability in Agentic AI”* survey, defining intrinsic, post-hoc, and causal transparency methods.  
- Designed **trust-weighted interpretability** mechanisms for alignment auditing and safety verification in reasoning systems.

#### 💡 **Vector Institute** — *Machine Learning Associate*  
*May 2025 – Sept 2025*  
- Built a **LangChain + Qdrant RAG pipeline** to semantically index 1,000-page healthcare billing documents (−80% lookup time).  
- Implemented **hybrid retrieval** (OpenAI Embeddings + BM25) with rule-based safety filters (Recall@5 = 0.9, BERTScore = 0.8).  
- Delivered demos to leadership showcasing **responsible AI deployment pipelines** aligned with internal governance standards.

#### 🧮 **Genellipse** — *Data Scientist*  
*Aug 2024 – Dec 2024*  
- Fine-tuned **Gemma 2B**, **LLaMA 3**, and **Mistral 7B** on 600 SEC 10-Q filings from 75 companies.  
- Automated data pipelines with EDGAR API and AWS S3 to create structured datasets for model training.  
- Delivered a governance-compliant PoC for **financial text generation**, achieving 40% structured accuracy while maintaining transparency and auditability.

#### 🤖 **AIFocal Inc.** — *AI Engineer Intern*  
*Sept 2023 – Oct 2023*  
- Built a **PDF-aware QA chatbot** using Gemma 2B and LangChain RAG integrated with safety filters.  
- Designed **semantic prompt routing** for multi-query reasoning, reducing hallucination rates by 12%.  
- Achieved 85% accuracy on long-context summarization QA benchmarks.

#### 📊 **Tata Consultancy Services** — *Assistant System Engineer*  
*Oct 2021 – Dec 2022*  
- Developed telecom churn prediction models (Random Forest, XGBoost) with 87% accuracy.  
- Automated feature engineering and visualization pipelines, improving real-time decision analytics.

---

### 🧩 Projects
- 🩺 **Clinical Note Generator** – Fine-tuned LLMs for mental-health documentation using structured SOAP/DAP templates.  
- 📊 **GenAI Billing Assistant** – Multi-agent RAG system integrating SQL data and unstructured regulatory text for claim validation.  
- ⚙️ **SEC Filing Automation** – Graph-based linking of financial tables and textual disclosures for explainable report generation.  
- 🤝 **AIXpert Survey Paper** – Co-authored the *Explainability and Interpretability in Agentic AI* survey (2025).

---

### 🏅 Highlights
- 🎓 M.Eng., University of Waterloo — GPA 3.90 / 4.00  
- 📘 Co-author — *Explainability and Interpretability in Agentic AI: A Survey Across the Agentic Loop (2025)*  
- 🔍 **AAAI 2026 Reviewer — LLM Governance & AI Safety (AIGOV Workshop)**  
- 🧱 Hands-on with LoRA/QLoRA, Flash-Attention-2, and A100 distributed fine-tuning  
- 🌐 Open-source contributor to LangChain and CrewAI-based agentic frameworks  
- 🧠 Focus Areas: **AI Safety** · **Governance** · **Explainability** · **Trust Mechanisms** · **Responsible GenAI**

---

### 📫 Contact
📧 [sindhu.chaduvula.21@gmail.com](mailto:sindhu.chaduvula.21@gmail.com)  
🔗 [LinkedIn](https://linkedin.com/in/sindhujachaduvula) | [GitHub](https://github.com/sindhujachaduvula)
